{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "import numpy as np\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.importar_datos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se utilizan los mejores modelos obtenidos para XGBoost, Random Forest y SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest():\n",
    "    preprocessor = pp.PreprocessingLE()\n",
    "    model = RandomForestClassifier(random_state=pp.RANDOM_STATE, \n",
    "                                   n_jobs=-1, \n",
    "                                   max_depth=8, \n",
    "                                   min_samples_leaf=1, \n",
    "                                   min_samples_split=14, \n",
    "                                   max_features=7)\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                         (\"model\", model)\n",
    "                         ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost():\n",
    "    pipeline = Pipeline([\n",
    "    (\"preprocessor\", pp.PreprocessingLE()),\n",
    "    (\"model\", XGBClassifier(use_label_encoder=False, scale_pos_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    "                            objective=\"binary:logistic\", n_estimators=1000, learning_rate=0.01, n_jobs=-1,\n",
    "                            eval_metric=\"logloss\", min_child_weight=6, max_depth=6, reg_alpha=0.05))\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm():\n",
    "    preprocessor = pp.PreprocessingSE()\n",
    "    model = SVC(kernel='rbf', random_state=pp.RANDOM_STATE, C=1, gamma='scale', probability=True)\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                     (\"model\", model)\n",
    "                     ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se utiliza un ensamble de tipo Stacking\n",
    "- Como estimador final se usa un GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_gaussian(var_smoothing=1e-9):\n",
    "    estimadores = [('svm', svm()), ('xgboost', xgboost()), ('random_forest', random_forest())]\n",
    "    cv = utils.kfold_for_cross_validation()\n",
    "    stacking = StackingClassifier(estimators=estimadores, final_estimator=GaussianNB(var_smoothing=var_smoothing), \n",
    "                                  stack_method=\"predict_proba\", cv=cv)\n",
    "    return stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = stacking_gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.metricas_cross_validation(X, y, stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mismo tipo de ensamble\n",
    "- Mismo estimador final que en el modelo 1, pero se busca un mejor hiperparámetro para el GaussianNB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = stacking_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {\n",
    "#    'final_estimator__var_smoothing': [1e-9, 1e-7, 1e-6, 1e-3, 5e-3, 1e-2, 0.1, 0.3],\n",
    "#    'xgboost__model__use_label_encoder': [False], \n",
    "#    'xgboost__model__scale_pos_weight': [1], \n",
    "#    'xgboost__model__subsample': [0.8], \n",
    "#    'xgboost__model__colsample_bytree': [0.8],\n",
    "#    'xgboost__model__objective': [\"binary:logistic\"], \n",
    "#    'xgboost__model__n_estimators': [1000], \n",
    "#    'xgboost__model__learning_rate': [0.01], \n",
    "#    'xgboost__model__n_jobs': [-1],                       \n",
    "#    'xgboost__model__eval_metric': [\"logloss\"], \n",
    "#    'xgboost__model__min_child_weight': [6], \n",
    "#    'xgboost__model__max_depth': [6], \n",
    "#    'xgboost__model__reg_alpha': [0.05],\n",
    "#    'svm__model__C': [1], \n",
    "#    'svm__model__gamma': ['scale'], \n",
    "#    'svm__model__probability': [True],\n",
    "#    'svm__model__random_state': [pp.RANDOM_STATE], \n",
    "#    'random_forest__model__n_jobs': [-1], \n",
    "#    'random_forest__model__max_depth': [11], \n",
    "#    'random_forest__model__min_samples_leaf': [1], \n",
    "#    'random_forest__model__min_samples_split': [13]\n",
    "#}\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=8, random_state=pp.RANDOM_STATE, shuffle=True)\n",
    "#gscv_gaussian = GridSearchCV(\n",
    "#    stacking, params, scoring='roc_auc', n_jobs=-1, cv=cv, return_train_score=True\n",
    "#).fit(X, y)\n",
    "#print(gscv_gaussian.best_score_)\n",
    "#print(gscv_gaussian.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el Notebook de XGBoost, el Grid Search tarda mucho en correr a pesar de que la grilla es pequeña (solo final_estimator__var_smoothing tiene más de un valor). Para evitar esto se prueba el var_smoothing a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = [1e-9, 1e-8, 1e-7, 1e-6, 1e-3, 5e-3, 1e-2, 3e-2, 5e-2, 0.1, 0.3]\n",
    "max_score_value = 0\n",
    "optimal_var_smothing = 0\n",
    "for var_smothing in options:\n",
    "    stacking = stacking_gaussian(var_smothing)\n",
    "    cv = utils.kfold_for_cross_validation()\n",
    "    scoring_metrics = [\"roc_auc\"]\n",
    "    scores_for_model = cross_validate(stacking, X, y, cv=cv, scoring=scoring_metrics)\n",
    "    roc_auc_score_value = scores_for_model['test_roc_auc'].mean()\n",
    "    print(f\"Corrio con var_smothing: {var_smothing}, roc_auc_score: {roc_auc_score_value}\")\n",
    "    if roc_auc_score_value > max_score_value:\n",
    "        max_score_value = roc_auc_score_value\n",
    "        optimal_var_smothing = var_smothing\n",
    "print(f'var_smothing: {optimal_var_smothing}')\n",
    "print(f'roc_auc_score_value: {max_score_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = stacking_gaussian(0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.metricas_cross_validation(X, y, stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensamble de tipo Voting (soft voting).\n",
    "- Se utilizan los mismos modelos que en los ensambles de tipo Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_classifier(voting=\"soft\"):\n",
    "    estimadores = [('svm', svm()), ('xgboost', xgboost()), ('random_forest', random_forest())]\n",
    "    stacking = VotingClassifier(estimators=estimadores, n_jobs=-1, voting=voting)\n",
    "    return stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = voting_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.metricas_cross_validation(X, y, voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eligió el [Modelo 1](#Modelo-1), dado que es el modelo que tiene mejores métricas en general (especialmente en Recall y F1 Score). En cuanto al Roc Auc, son los 3 muy parecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, \n",
    "                                                    random_state=pp.RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = stacking_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "columnas = ['AUC_ROC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "results = [roc_auc_score(y_test, y_pred_proba)]\n",
    "results += [s(y_test, y_pred) for s in scores]\n",
    "display(pd.DataFrame([results], columns=columnas).style.hide_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = utils.entrenar_y_realizar_prediccion_final_con_metricas(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción HoldOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.predecir_holdout_y_generar_csv(pipeline, 'Predicciones/9-Ensambles.csv')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
