{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import preprocessing as pp\n",
    "import numpy as np\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "seed = 100\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = utils.importar_datos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se utilizan los mejores modelos obtenidos para XGBoost, Random Forest y SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest():\n",
    "    preprocessor = pp.PreprocessingLE()\n",
    "    model = RandomForestClassifier(random_state=pp.RANDOM_STATE, \n",
    "                                   n_jobs=-1, \n",
    "                                   max_depth=8, \n",
    "                                   min_samples_leaf=1, \n",
    "                                   min_samples_split=14, \n",
    "                                   max_features=7)\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                         (\"model\", model)\n",
    "                         ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost():\n",
    "    pipeline = Pipeline([\n",
    "    (\"preprocessor\", pp.PreprocessingLE()),\n",
    "    (\"model\", XGBClassifier(use_label_encoder=False, scale_pos_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    "                            objective=\"binary:logistic\", n_estimators=1000, learning_rate=0.01, n_jobs=-1,\n",
    "                            eval_metric=\"logloss\", min_child_weight=6, max_depth=6, reg_alpha=0.05))\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm():\n",
    "    preprocessor = pp.PreprocessingSE()\n",
    "    model = SVC(kernel='rbf', random_state=pp.RANDOM_STATE, C=1, gamma='scale', probability=True)\n",
    "    pipeline = Pipeline([(\"preprocessor\", preprocessor), \n",
    "                     (\"model\", model)\n",
    "                     ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se utiliza un ensamble de tipo Stacking\n",
    "- Como estimador final se usa un GaussianNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking_gaussian(var_smoothing=1e-9):\n",
    "    estimadores = [('svm', svm()), ('xgboost', xgboost()), ('random_forest', random_forest())]\n",
    "    cv = utils.kfold_for_cross_validation()\n",
    "    stacking = StackingClassifier(estimators=estimadores, final_estimator=GaussianNB(var_smoothing=var_smoothing), \n",
    "                                  stack_method=\"predict_proba\", cv=cv)\n",
    "    return stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = stacking_gaussian()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Oof</th>\n",
       "      <th>Max</th>\n",
       "      <th>Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc auc</th>\n",
       "      <td>0.867432</td>\n",
       "      <td>0.028982</td>\n",
       "      <td>0.861596</td>\n",
       "      <td>0.902377</td>\n",
       "      <td>0.817912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.816473</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>0.816479</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.783457</td>\n",
       "      <td>0.037506</td>\n",
       "      <td>0.781690</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.710526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.723178</td>\n",
       "      <td>0.025118</td>\n",
       "      <td>0.723127</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.684211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1 score</th>\n",
       "      <td>0.751482</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.751269</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std       Oof       Max       Min\n",
       "roc auc    0.867432  0.028982  0.861596  0.902377  0.817912\n",
       "accuracy   0.816473  0.019377  0.816479  0.840000  0.770000\n",
       "precision  0.783457  0.037506  0.781690  0.848485  0.710526\n",
       "recall     0.723178  0.025118  0.723127  0.763158  0.684211\n",
       "f1 score   0.751482  0.022270  0.751269  0.777778  0.701299"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.metricas_cross_validation(X, y, stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mismo tipo de ensamble\n",
    "- Mismo estimador final que en el modelo 1, pero se busca un mejor hiperparámetro para el GaussianNB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = stacking_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params = {\n",
    "#    'final_estimator__var_smoothing': [1e-9, 1e-7, 1e-6, 1e-3, 5e-3, 1e-2, 0.1, 0.3],\n",
    "#    'xgboost__model__use_label_encoder': [False], \n",
    "#    'xgboost__model__scale_pos_weight': [1], \n",
    "#    'xgboost__model__subsample': [0.8], \n",
    "#    'xgboost__model__colsample_bytree': [0.8],\n",
    "#    'xgboost__model__objective': [\"binary:logistic\"], \n",
    "#    'xgboost__model__n_estimators': [1000], \n",
    "#    'xgboost__model__learning_rate': [0.01], \n",
    "#    'xgboost__model__n_jobs': [-1],                       \n",
    "#    'xgboost__model__eval_metric': [\"logloss\"], \n",
    "#    'xgboost__model__min_child_weight': [6], \n",
    "#    'xgboost__model__max_depth': [6], \n",
    "#    'xgboost__model__reg_alpha': [0.05],\n",
    "#    'svm__model__C': [1], \n",
    "#    'svm__model__gamma': ['scale'], \n",
    "#    'svm__model__probability': [True],\n",
    "#    'svm__model__random_state': [pp.RANDOM_STATE], \n",
    "#    'random_forest__model__n_jobs': [-1], \n",
    "#    'random_forest__model__max_depth': [11], \n",
    "#    'random_forest__model__min_samples_leaf': [1], \n",
    "#    'random_forest__model__min_samples_split': [13]\n",
    "#}\n",
    "\n",
    "#cv = StratifiedKFold(n_splits=8, random_state=pp.RANDOM_STATE, shuffle=True)\n",
    "#gscv_gaussian = GridSearchCV(\n",
    "#    stacking, params, scoring='roc_auc', n_jobs=-1, cv=cv, return_train_score=True\n",
    "#).fit(X, y)\n",
    "#print(gscv_gaussian.best_score_)\n",
    "#print(gscv_gaussian.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el Notebook de XGBoost, el Grid Search tarda mucho en correr a pesar de que la grilla es pequeña (solo final_estimator__var_smoothing tiene más de un valor). Para evitar esto se prueba el var_smoothing a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "options = [1e-9, 1e-8, 1e-7, 1e-6, 1e-3, 5e-3, 1e-2, 3e-2, 5e-2, 0.1, 0.3]\n",
    "max_score_value = 0\n",
    "optimal_var_smothing = 0\n",
    "for var_smothing in options:\n",
    "    stacking = stacking_gaussian(var_smothing)\n",
    "    cv = utils.kfold_for_cross_validation()\n",
    "    scoring_metrics = [\"roc_auc\"]\n",
    "    scores_for_model = cross_validate(stacking, X, y, cv=cv, scoring=scoring_metrics)\n",
    "    roc_auc_score_value = scores_for_model['test_roc_auc'].mean()\n",
    "    print(f\"Corrio con var_smothing: {var_smothing}, roc_auc_score: {roc_auc_score_value}\")\n",
    "    if roc_auc_score_value > max_score_value:\n",
    "        max_score_value = roc_auc_score_value\n",
    "        optimal_var_smothing = var_smothing\n",
    "print(f'var_smothing: {optimal_var_smothing}')\n",
    "print(f'roc_auc_score_value: {max_score_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking = stacking_gaussian(0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.metricas_cross_validation(X, y, stacking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensamble de tipo Voting (soft voting).\n",
    "- Se utilizan los mismos modelos que en los ensambles de tipo Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_classifier(voting=\"soft\"):\n",
    "    estimadores = [('svm', svm()), ('xgboost', xgboost()), ('random_forest', random_forest())]\n",
    "    stacking = VotingClassifier(estimators=estimadores, n_jobs=-1, voting=voting)\n",
    "    return stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting = voting_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.metricas_cross_validation(X, y, voting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eligió el [Modelo 1](#Modelo-1), dado que es el modelo que tiene mejores métricas en general (especialmente en Recall y F1 Score). En cuanto al Roc Auc, son los 3 muy parecidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, \n",
    "                                                    random_state=pp.RANDOM_STATE, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = stacking_gaussian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "columnas = ['AUC_ROC', 'Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "results = [roc_auc_score(y_test, y_pred_proba)]\n",
    "results += [s(y_test, y_pred) for s in scores]\n",
    "display(pd.DataFrame([results], columns=columnas).style.hide_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = utils.entrenar_y_realizar_prediccion_final_con_metricas(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicción HoldOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.predecir_holdout_y_generar_csv(pipeline, 'Predicciones/9-Ensambles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
